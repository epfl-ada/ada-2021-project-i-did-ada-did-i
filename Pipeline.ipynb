{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:ada] *",
      "language": "python",
      "name": "conda-env-ada-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "asFKAikJRb6d",
        "T6U337IMRoHi",
        "8jhabGmPRrG7"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "718c829d-a156-4c6f-8102-a47fbe43ddc4"
      },
      "source": [
        "# Proposed pipeline"
      ],
      "id": "718c829d-a156-4c6f-8102-a47fbe43ddc4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f58b18c-b3c4-41a7-a7fb-ba11a1b435cc"
      },
      "source": [
        "## A) Loading the data"
      ],
      "id": "6f58b18c-b3c4-41a7-a7fb-ba11a1b435cc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XesiVsJzZDWF"
      },
      "source": [
        "### 1. Quotebank"
      ],
      "id": "XesiVsJzZDWF"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H_-gPqAYI01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d032b712-7f5c-4d2a-ebe0-d604827733b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import bz2\n",
        "import json\n",
        "import copy\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "from bs4 import BeautifulSoup as soup\n",
        "import urllib.request as ul\n",
        "from collections import Counter\n",
        "from tld import get_fld\n",
        "import string\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download('vader_lexicon')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer  # VADER is better for short sentences, but we only have this so we use just that.\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "id": "0H_-gPqAYI01",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mqkbmYdsyDzX",
        "outputId": "402c2402-e012-4c23-9b53-bd627a334a89"
      },
      "source": [
        "pd.__version__"
      ],
      "id": "mqkbmYdsyDzX",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.5'"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AE0Dnnxuyiq5",
        "outputId": "58baee95-a967-40d0-b629-2005940c7466"
      },
      "source": [
        "!pip install pandas==1.0.5"
      ],
      "id": "AE0Dnnxuyiq5",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas==1.0.5 in /usr/local/lib/python3.7/dist-packages (1.0.5)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==1.0.5) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->pandas==1.0.5) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk5xa0msRwNe",
        "outputId": "af9742df-e523-402f-99eb-7e339b22391e"
      },
      "source": [
        "!pip install tld"
      ],
      "id": "hk5xa0msRwNe",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tld\n",
            "  Downloading tld-0.12.6-py37-none-any.whl (412 kB)\n",
            "\u001b[?25l\r\u001b[K     |▉                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 24.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 40 kB 12.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 61 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 133 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 143 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 153 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 163 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 174 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 184 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 194 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 204 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 215 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 225 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 235 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 245 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 256 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 266 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 276 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 286 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 296 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 307 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 317 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 327 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 337 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 348 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 358 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 368 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 378 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 389 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 399 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 409 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 412 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: tld\n",
            "Successfully installed tld-0.12.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuONXghXYYEx"
      },
      "source": [
        "# Load & format quotes from 2020\n",
        "#change on everyone's computer according to personal path\n",
        "path_to_file = '/content/drive/MyDrive/ADA/Quotebank/quotes-2020.json.bz2' \n",
        "\n",
        "list_of_quotes_dict = []\n",
        "count = 0\n",
        "sample_size = 10000  # Sample chosen for current experiments\n",
        "\n",
        "# Open the 2020 quotebank\n",
        "with bz2.open(path_to_file, 'rb') as s_file:\n",
        "    for instance in s_file:\n",
        "        if count == sample_size:\n",
        "            break\n",
        "        #print(instance)\n",
        "        decoded = json.loads(instance.decode('utf-8'))  # Decode each instance into a dictionary\n",
        "        #print(decoded[\"quoteID\"])\n",
        "        list_of_quotes_dict.append(decoded)\n",
        "        count += 1\n",
        "\n",
        "df_quotes = pd.DataFrame(list_of_quotes_dict)  # Turn list of entries into dataframe"
      ],
      "id": "cuONXghXYYEx",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q31R0GjsmFUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a287c4c9-e7f0-4c39-916e-8708033e15c4"
      },
      "source": [
        "df_quotes.loc[0:4,'urls'].tolist()"
      ],
      "id": "Q31R0GjsmFUP",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['http://israelnationalnews.com/News/News.aspx/275210'],\n",
              " ['http://thehill.com/opinion/international/478224-saudi-critics-should-revisit-sue-myricks-wake-up-america-agenda'],\n",
              " ['https://indianexpress.com/article/business/economy/cbi-to-court-gst-officials-taking-cut-from-transporters-6261429/'],\n",
              " ['https://patriotpost.us/opinion/68622-trump-budget-a-cut-above-the-rest-2020-02-15',\n",
              "  'https://www.lifenews.com/2020/02/15/nancy-pelosi-and-democrats-push-bill-to-overturn-every-pro-life-law-saving-babies-from-abortions/'],\n",
              " ['https://people.com/parents/meghan-king-edmonds-not-using-frozen-embryos-with-jim-edmonds/',\n",
              "  'https://people.com/parents/meghan-king-edmonds-stepkids-poisoned-false-information-about-her-jim-edmonds/',\n",
              "  'https://www.usmagazine.com/celebrity-news/news/meghan-king-edmonds-says-shes-been-blocked-from-stepkids/',\n",
              "  'https://people.com/tv/meghan-king-edmonds-jim-edmonds-came-with-baggage-kids/']]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFwxb1BwZGmK"
      },
      "source": [
        "### 2. Wikidata\n",
        "\n"
      ],
      "id": "RFwxb1BwZGmK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymYSIcOjZKAE"
      },
      "source": [
        "# Load the speaker attributes \n",
        "wikidata_speakers = pd.read_parquet('/content/drive/MyDrive/ADA/Project datasets/speaker_attributes.parquet')"
      ],
      "id": "ymYSIcOjZKAE",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "RfgsQW2woggT",
        "outputId": "cc8edfa9-7245-437e-ae21-3d1251c7f81f"
      },
      "source": [
        "wikidata_speakers.sample(3)"
      ],
      "id": "RfgsQW2woggT",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aliases</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>nationality</th>\n",
              "      <th>gender</th>\n",
              "      <th>lastrevid</th>\n",
              "      <th>ethnic_group</th>\n",
              "      <th>US_congress_bio_ID</th>\n",
              "      <th>occupation</th>\n",
              "      <th>party</th>\n",
              "      <th>academic_degree</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>candidacy</th>\n",
              "      <th>type</th>\n",
              "      <th>religion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>659504</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>995628862</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q65839036</td>\n",
              "      <td>Ye Shangqing</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6533342</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1362579085</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q1650915]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q91344219</td>\n",
              "      <td>Christina Fernandes</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4028916</th>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q6581072]</td>\n",
              "      <td>1294008365</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q15936497]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q63844217</td>\n",
              "      <td>Janneke Verheijen</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        aliases date_of_birth nationality  ... candidacy  type religion\n",
              "659504     None          None        None  ...      None  item     None\n",
              "6533342    None          None        None  ...      None  item     None\n",
              "4028916    None          None        None  ...      None  item     None\n",
              "\n",
              "[3 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT0PuiX7WG-O"
      },
      "source": [
        "## B) Data exploration"
      ],
      "id": "mT0PuiX7WG-O"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3tJUwgkMQcGG"
      },
      "source": [
        "### 1. Frequency of domains"
      ],
      "id": "3tJUwgkMQcGG"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xd-x839Q7ZF"
      },
      "source": [
        "We want to compute the number of quotes per news outlet in order to choose the most important for our analysis of the potential impact of the political orientation (we can not perform this analysis on the whole dataset as there is no way to find the political orientation of every news outlets).\n",
        "\n",
        "The first step is to extract the domain from the url. For this task we use the tld library "
      ],
      "id": "2xd-x839Q7ZF"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSbzytTpR38Q"
      },
      "source": [
        "The *get_domain* function return the domain name from a url.\n",
        "\n",
        "Example: *get_domain(\"https://stackoverflow.com/questions/ \")* returns stackoverflow.com\n",
        "\n",
        "The *domain_counting* function takes the list of urls of one quotes and count the number of domains using *get_domain* and the function *Counter* from the library Collection."
      ],
      "id": "lSbzytTpR38Q"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUHl0HpIjGK1"
      },
      "source": [
        "def get_domain(url):\n",
        "    return get_fld(url)\n",
        "\n",
        "def domain_counting(urls):\n",
        "    domain_list = [] #we store the domain in this list\n",
        "    for url in urls:\n",
        "        domain_list.append(get_domain(url))\n",
        "    return Counter(domain_list)"
      ],
      "id": "FUHl0HpIjGK1",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vl8daAYklh6"
      },
      "source": [
        "path_to_file = '/content/drive/MyDrive/ADA/Quotebank/quotes-2020.json.bz2' \n",
        "\n",
        "domains_count = Counter()\n",
        "\n",
        "df_test = pd.read_json(path_to_file, lines=True, compression='bz2', chunksize=10000) #code used to load the data by chunks\n",
        "for chunk in df_test:\n",
        "        domains = chunk['urls'].apply(domain_counting)\n",
        "        domains_count = domains_count + domains.sum() # chunk['urls'].apply(..) return a series containing the result of Counter(domain_list)\n",
        "                                                      # so we have to use .sum() to obtain a Counter object."
      ],
      "id": "6vl8daAYklh6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgKUjFSVjzfb",
        "outputId": "6ee9f34b-0f43-44b8-fcdd-99b974f6daf7"
      },
      "source": [
        "domains_count.most_common(20)"
      ],
      "id": "SgKUjFSVjzfb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('einnews.com', 267567),\n",
              " ('msn.com', 241598),\n",
              " ('news965.com', 127998),\n",
              " ('wokv.com', 119616),\n",
              " ('breitbart.com', 98428),\n",
              " ('washingtontimes.com', 81833),\n",
              " ('wsbradio.com', 77257),\n",
              " ('indiatimes.com', 75690),\n",
              " ('nbcsports.com', 72913),\n",
              " ('nytimes.com', 70478),\n",
              " ('foxnews.com', 66660),\n",
              " ('sfgate.com', 64866),\n",
              " ('gamereactor.eu', 57670),\n",
              " ('nbcnews.com', 55788),\n",
              " ('smh.com.au', 54683),\n",
              " ('newsok.com', 54674),\n",
              " ('krmg.com', 54602),\n",
              " ('stuff.co.nz', 53072),\n",
              " ('timesofisrael.com', 52930),\n",
              " ('news12.com', 52282)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5s3pgMbGSg7o"
      },
      "source": [
        "### 2. Wikidata\n",
        "\n"
      ],
      "id": "5s3pgMbGSg7o"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FV51WO-oAIn"
      },
      "source": [
        "#### Check how many QIDs there are per speaker:\n",
        "\n",
        "With a sample consisting of the first 10,000 quotes of the 2020 dataset, we can read from the histogram that there is a majority of speakers who have no wikidata page (3425), and one wikidata page (4832). Then the frequency of QID number decreases rapidly (682 for two QID, 285 for three...), however there are still 9 speakers having 20 different QIDs and one speaker with 257 (whose name is *Wang Yi*, current maximum). We will need to figure out a solution for dealing with the speakers having more than one QID. "
      ],
      "id": "2FV51WO-oAIn"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "HY04RJircwbt",
        "outputId": "96f0a5c1-27fb-438a-b20e-8b4200ea25f6"
      },
      "source": [
        "# Check QID list's length of every loaded quotes \n",
        "length_qids = np.zeros(len(df_quotes))\n",
        "for idx, qids in enumerate(df_quotes[\"qids\"].values):\n",
        "  length_qids[idx] = len(qids)\n",
        "# Plot a histogram with log-scale on Y axis\n",
        "plt.hist(length_qids, bins=int(np.max(length_qids)))\n",
        "plt.yscale('log')\n",
        "plt.grid('on')\n",
        "plt.xlabel(\"Number of QID elements per speaker\")\n",
        "plt.ylabel(\"Frequency (log-scale)\")\n",
        "plt.title(\"Histogram of the number of QID per speaker\")\n",
        "#plt.xlim(0, 30) # Uncomment for focusing on a specific region \n",
        "plt.show()"
      ],
      "id": "HY04RJircwbt",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Le4mUaL0lOoV",
        "outputId": "fcbd57ab-89f3-4c42-9d03-cf0d6263c8a4"
      },
      "source": [
        "# Display the frequency using a dataframe instead of a histogram\n",
        "val, freq = np.unique(length_qids, return_counts=True)\n",
        "df_QID_freq = pd.DataFrame(data={\"Nb. of QID\":val, \"Frequency\":freq})\n",
        "df_QID_freq.head(5)"
      ],
      "id": "Le4mUaL0lOoV",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Nb. of QID</th>\n",
              "      <th>Frequency</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>3425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>4832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>663</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Nb. of QID  Frequency\n",
              "0         0.0       3425\n",
              "1         1.0       4832\n",
              "2         2.0        663\n",
              "3         3.0        285\n",
              "4         4.0        170"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rb_U0pJQ2KYj"
      },
      "source": [
        "#### Load the human interpretable labels"
      ],
      "id": "rb_U0pJQ2KYj"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "Jfi6eNRd2V6h",
        "outputId": "9854ec94-7b1a-41fe-fbde-aeabc10a52eb"
      },
      "source": [
        "path_to_file = '/content/drive/MyDrive/ADA/Project datasets/wikidata_labels_descriptions_quotebank.csv.bz2'\n",
        "# Directly use the built-in pandas function as the CSV is quite small \n",
        "df_labels_wiki = pd.read_csv(path_to_file,  encoding='utf-8', compression=\"bz2\")\n",
        "df_labels_wiki.head(5)"
      ],
      "id": "Jfi6eNRd2V6h",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QID</th>\n",
              "      <th>Label</th>\n",
              "      <th>Description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q31</td>\n",
              "      <td>Belgium</td>\n",
              "      <td>country in western Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q45</td>\n",
              "      <td>Portugal</td>\n",
              "      <td>country in southwestern Europe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q75</td>\n",
              "      <td>Internet</td>\n",
              "      <td>global system of connected computer networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q148</td>\n",
              "      <td>People's Republic of China</td>\n",
              "      <td>sovereign state in East Asia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q155</td>\n",
              "      <td>Brazil</td>\n",
              "      <td>country in South America</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    QID  ...                                   Description\n",
              "0   Q31  ...                     country in western Europe\n",
              "1   Q45  ...                country in southwestern Europe\n",
              "2   Q75  ...  global system of connected computer networks\n",
              "3  Q148  ...                  sovereign state in East Asia\n",
              "4  Q155  ...                      country in South America\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idplwSqSTGeR"
      },
      "source": [
        "The function `retrieve_wikidata_properties` simply returns the wikidata properties of the given person."
      ],
      "id": "idplwSqSTGeR"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sKnuNufOY9zI"
      },
      "source": [
        "def retrieve_wikidata_properties(person):\n",
        "  # This function simply returns the wikidata properties of the given person\n",
        "  return wikidata_speakers[wikidata_speakers[\"id\"]==person]"
      ],
      "id": "sKnuNufOY9zI",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I9LFOlSTlS9"
      },
      "source": [
        "The function `human_readable_properties` converts the QIDs into human readable format."
      ],
      "id": "3I9LFOlSTlS9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK4gM8npsP9Y"
      },
      "source": [
        "def human_readable_properties(data, property):\n",
        "  list_QID = (data.iloc[0][property])\n",
        "  list_values = []\n",
        "  # Start by testing whether there is value\n",
        "  if not(list_QID is None):\n",
        "    # As there might be several values per property, we iterate on them\n",
        "    for idx, QID in enumerate(list_QID):\n",
        "      # Check whether the QID is corrupted, i.e. do not start by Q or less than two characters \n",
        "      if len(QID) >= 2 and QID[0] == 'Q':\n",
        "        # Retrieve the Label (not description) of the QID item in the dataframe containing wikidata label\n",
        "        # In df_labels_wiki, select the row that corresponds to the QID of interst \n",
        "        selector = df_labels_wiki[\"QID\"] == QID \n",
        "        # Then extract the label of the QID/item of interest\n",
        "        list_values.append(df_labels_wiki[selector].iloc[0][\"Label\"])\n",
        "      else:\n",
        "        warnings.warn(\"This is a corrupted QID, no value is returned!\")\n",
        "    return list_values\n",
        "  else:\n",
        "    warnings.warn(\"There is no value for this property!\")\n",
        "    return None  "
      ],
      "id": "zK4gM8npsP9Y",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHuixGYMWK2U"
      },
      "source": [
        "## C) Data preparation"
      ],
      "id": "EHuixGYMWK2U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj0GTIluPOV8"
      },
      "source": [
        "### 1. Get each speaker's vocabulary"
      ],
      "id": "Dj0GTIluPOV8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4b549892-64b6-4244-806d-57187fbcd962"
      },
      "source": [
        "#### I) Tokenise the sentences (turn them into single words)\n",
        "\n",
        "* [Some interesting information on tokenization](https://towardsdatascience.com/overview-of-nlp-tokenization-algorithms-c41a7d5ec4f9)\n",
        "* [Multi-Word Expression tokenizer](https://www.nltk.org/_modules/nltk/tokenize/mwe.html)"
      ],
      "id": "4b549892-64b6-4244-806d-57187fbcd962"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f88da2ff-3939-4cee-a7ad-4775de89537d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "7e8f2607-cf44-4673-f628-df2d98cb3756"
      },
      "source": [
        "df_quotes[\"tokenized_quote\"] = df_quotes.quotation.apply(word_tokenize)  # Tokenize quotes and add them in the dataframe as new column\n",
        "df_quotes.head()"
      ],
      "id": "f88da2ff-3939-4cee-a7ad-4775de89537d",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "      <th>phase</th>\n",
              "      <th>tokenized_quote</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-28-000082</td>\n",
              "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-01-28 08:04:05</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.7272], [Prime Minister Netanyahu, 0....</td>\n",
              "      <td>[http://israelnationalnews.com/News/News.aspx/...</td>\n",
              "      <td>E</td>\n",
              "      <td>[[, D, ], espite, the, efforts, of, the, partn...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.768, 'pos': 0.232, 'comp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-16-000088</td>\n",
              "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
              "      <td>Sue Myrick</td>\n",
              "      <td>[Q367796]</td>\n",
              "      <td>2020-01-16 12:00:13</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Sue Myrick, 0.8867], [None, 0.0992], [Ron Wy...</td>\n",
              "      <td>[http://thehill.com/opinion/international/4782...</td>\n",
              "      <td>E</td>\n",
              "      <td>[[, Department, of, Homeland, Security, ], was...</td>\n",
              "      <td>{'neg': 0.184, 'neu': 0.579, 'pos': 0.237, 'co...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-02-10-000142</td>\n",
              "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-10 23:45:54</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.8926], [Prakash Rai, 0.1074]]</td>\n",
              "      <td>[https://indianexpress.com/article/business/ec...</td>\n",
              "      <td>E</td>\n",
              "      <td>[..., He, (, Madhav, ), also, disclosed, that,...</td>\n",
              "      <td>{'neg': 0.113, 'neu': 0.84, 'pos': 0.046, 'com...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-02-15-000053</td>\n",
              "      <td>... [ I ] f it gets to the floor,</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-15 14:12:51</td>\n",
              "      <td>2</td>\n",
              "      <td>[[None, 0.581], [Andy Harris, 0.4191]]</td>\n",
              "      <td>[https://patriotpost.us/opinion/68622-trump-bu...</td>\n",
              "      <td>E</td>\n",
              "      <td>[..., [, I, ], f, it, gets, to, the, floor, ,]</td>\n",
              "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-24-000168</td>\n",
              "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
              "      <td>Meghan King Edmonds</td>\n",
              "      <td>[Q20684375]</td>\n",
              "      <td>2020-01-24 20:37:09</td>\n",
              "      <td>4</td>\n",
              "      <td>[[Meghan King Edmonds, 0.5446], [None, 0.2705]...</td>\n",
              "      <td>[https://people.com/parents/meghan-king-edmond...</td>\n",
              "      <td>E</td>\n",
              "      <td>[[, I, met, them, ], when, they, just, turned,...</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.877, 'pos': 0.123, 'comp...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             quoteID  ...                                          sentiment\n",
              "0  2020-01-28-000082  ...  {'neg': 0.0, 'neu': 0.768, 'pos': 0.232, 'comp...\n",
              "1  2020-01-16-000088  ...  {'neg': 0.184, 'neu': 0.579, 'pos': 0.237, 'co...\n",
              "2  2020-02-10-000142  ...  {'neg': 0.113, 'neu': 0.84, 'pos': 0.046, 'com...\n",
              "3  2020-02-15-000053  ...  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "4  2020-01-24-000168  ...  {'neg': 0.0, 'neu': 0.877, 'pos': 0.123, 'comp...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FR6ucqZLJJ-O"
      },
      "source": [
        "Issue to solve: We need to find a way to reconstruct such abbreviated words like in the cell below..."
      ],
      "id": "FR6ucqZLJJ-O"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DV7ynXuJBUf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e02565c-ff0b-4df7-c572-fa68b2bde366"
      },
      "source": [
        "word_tokenize(\"it's, they're, can't\")"
      ],
      "id": "6DV7ynXuJBUf",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['it', \"'s\", ',', 'they', \"'re\", ',', 'ca', \"n't\"]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wd7LHvuHcK4X"
      },
      "source": [
        "Issue to solve: Handle words or letter in squared brackets, as we can see in the next cell\n",
        "* Single letter likely to belong to next word\n",
        "* One or more words in these brackets were not spoken by the speaker"
      ],
      "id": "wd7LHvuHcK4X"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urj7cQEEc4jw",
        "outputId": "55eb2ba9-e235-4b40-b6e1-a823c2472baa"
      },
      "source": [
        "df_quotes.loc[0][[\"quotation\", \"tokenized_quote\"]]"
      ],
      "id": "Urj7cQEEc4jw",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "quotation          [ D ] espite the efforts of the partners to cr...\n",
              "tokenized_quote    [[, D, ], espite, the, efforts, of, the, partn...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3NRt5zaCYKHA"
      },
      "source": [
        "#### II) Sentiment analysis"
      ],
      "id": "3NRt5zaCYKHA"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qvrir6JY_m0T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9563ab67-f788-44d1-9b8a-c3e2f6c2b269"
      },
      "source": [
        "sia = SentimentIntensityAnalyzer()\n",
        "#sia.polarity_scores(\"Hi, how are you?\")\n",
        "#sia.polarity_scores(\"Wow, NLTK is really powerful!\")\n",
        "sia.polarity_scores(\"You are a piece of shit!!\")  # Just a test for a negative sentence. Don't take it personnally"
      ],
      "id": "Qvrir6JY_m0T",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.6351, 'neg': 0.511, 'neu': 0.489, 'pos': 0.0}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFh0cOFSYSyI",
        "outputId": "7c08360c-5845-4e61-8229-ff2a08101c1c"
      },
      "source": [
        "df_quotes[\"sentiment\"] = df_quotes.quotation.apply(sia.polarity_scores)\n",
        "df_quotes.sentiment.head()"
      ],
      "id": "CFh0cOFSYSyI",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    {'neg': 0.0, 'neu': 0.768, 'pos': 0.232, 'comp...\n",
              "1    {'neg': 0.184, 'neu': 0.579, 'pos': 0.237, 'co...\n",
              "2    {'neg': 0.113, 'neu': 0.84, 'pos': 0.046, 'com...\n",
              "3    {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...\n",
              "4    {'neg': 0.0, 'neu': 0.877, 'pos': 0.123, 'comp...\n",
              "Name: sentiment, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9793a4a3-f51c-4777-ac02-703c1a1493ae"
      },
      "source": [
        "#### III) Remove punctuation and stopwords, lowercase everything"
      ],
      "id": "9793a4a3-f51c-4777-ac02-703c1a1493ae"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f773f9eb-1e66-4283-b677-fbdaef0581aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "5f7b7f28-e80b-4d83-a67a-165355938a47"
      },
      "source": [
        "#should be easy enough, don't mess it up\n",
        "\n",
        "EN_STOPWORDS = set(stopwords.words(\"english\"))  # English stopwords\n",
        "PUNCTUATION = set(string.punctuation)  # Punctuation\n",
        "\n",
        "def lowercase(l):\n",
        "    return [w.lower() for w in l]\n",
        "\n",
        "def remove_stopwords(l):\n",
        "    return [w for w in l if w.lower() not in EN_STOPWORDS]\n",
        "\n",
        "def remove_punctuation(l):\n",
        "    return [w for w in l if w not in PUNCTUATION]\n",
        "\n",
        "def process_tokens(l):\n",
        "    l = lowercase(l)  # Lowercase tokens\n",
        "    l = remove_stopwords(l)   # Remove stopwords from tokens\n",
        "    l = remove_punctuation(l)  # Remove punctuation from tokens\n",
        "    return l\n",
        "\n",
        "df_quotes[\"tokenized_quote\"] = df_quotes.tokenized_quote.apply(process_tokens)\n",
        "df_quotes[[\"quotation\", \"tokenized_quote\"]].head()"
      ],
      "id": "f773f9eb-1e66-4283-b677-fbdaef0581aa",
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quotation</th>\n",
              "      <th>tokenized_quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
              "      <td>[espite, efforts, partners, create, non-politi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
              "      <td>[department, homeland, security, livid, strong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
              "      <td>[..., madhav, also, disclosed, illegal, bribe,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>... [ I ] f it gets to the floor,</td>\n",
              "      <td>[..., f, gets, floor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
              "      <td>[met, turned, 4, 7, little, felt, like, full-b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           quotation                                    tokenized_quote\n",
              "0  [ D ] espite the efforts of the partners to cr...  [espite, efforts, partners, create, non-politi...\n",
              "1  [ Department of Homeland Security ] was livid ...  [department, homeland, security, livid, strong...\n",
              "2  ... He (Madhav) also disclosed that the illega...  [..., madhav, also, disclosed, illegal, bribe,...\n",
              "3                  ... [ I ] f it gets to the floor,                              [..., f, gets, floor]\n",
              "4  [ I met them ] when they just turned 4 and 7. ...  [met, turned, 4, 7, little, felt, like, full-b..."
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5480330b-861d-4771-9109-ce1231250c7d"
      },
      "source": [
        "#### IV) Lemmatize the words (i.e. {'eating', 'eat', 'ate'} -> \"eat\")\n",
        "* [Source](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python)"
      ],
      "id": "5480330b-861d-4771-9109-ce1231250c7d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bdd0370-09fa-494b-bda3-3ab87e7807bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "c7372026-e21f-4624-f963-ebd424a1e924"
      },
      "source": [
        "WNL = WordNetLemmatizer()\n",
        "\n",
        "def lem_words(l):\n",
        "    return [WNL.lemmatize(w, pos='v') for w in l]  # POS = part-of-speech, used to give context to the lemmatizer ('v' -> verb)\n",
        "\n",
        "df_quotes[\"tokenized_quote\"] = df_quotes.tokenized_quote.apply(lem_words)  # Lemmatize tokens\n",
        "df_quotes[[\"quotation\", \"tokenized_quote\"]].head()"
      ],
      "id": "3bdd0370-09fa-494b-bda3-3ab87e7807bb",
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quotation</th>\n",
              "      <th>tokenized_quote</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[ D ] espite the efforts of the partners to cr...</td>\n",
              "      <td>[espite, efforts, partner, create, non-politic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[ Department of Homeland Security ] was livid ...</td>\n",
              "      <td>[department, homeland, security, livid, strong...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>... He (Madhav) also disclosed that the illega...</td>\n",
              "      <td>[..., madhav, also, disclose, illegal, bribe, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>... [ I ] f it gets to the floor,</td>\n",
              "      <td>[..., f, get, floor]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[ I met them ] when they just turned 4 and 7. ...</td>\n",
              "      <td>[meet, turn, 4, 7, little, felt, like, full-bl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           quotation                                    tokenized_quote\n",
              "0  [ D ] espite the efforts of the partners to cr...  [espite, efforts, partner, create, non-politic...\n",
              "1  [ Department of Homeland Security ] was livid ...  [department, homeland, security, livid, strong...\n",
              "2  ... He (Madhav) also disclosed that the illega...  [..., madhav, also, disclose, illegal, bribe, ...\n",
              "3                  ... [ I ] f it gets to the floor,                               [..., f, get, floor]\n",
              "4  [ I met them ] when they just turned 4 and 7. ...  [meet, turn, 4, 7, little, felt, like, full-bl..."
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p60gp9kNRg3e"
      },
      "source": [
        "#### V) Pool tokens by speaker"
      ],
      "id": "p60gp9kNRg3e"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXxcCFmQR6d0"
      },
      "source": [
        "# TODO"
      ],
      "id": "jXxcCFmQR6d0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5bd42cd-f039-4f3c-8a8b-0c7a3f20116c"
      },
      "source": [
        "### 2. Assign an 'importance' score to each word"
      ],
      "id": "b5bd42cd-f039-4f3c-8a8b-0c7a3f20116c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-joRKQnYqVd"
      },
      "source": [
        "#### I) Cambridge dictionary CEFR score and register"
      ],
      "id": "k-joRKQnYqVd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdsbflcL0Ns2"
      },
      "source": [
        "def retrieve_CEFR_levels_registers(word):\n",
        "  \"\"\" Functions that retrives the ECFR level of the given word as well as its register\n",
        "      Input: \n",
        "        word - a string the word you want to inspect \n",
        "      Output: \n",
        "        levels - a numpy array containing strings, if empty no info was available\n",
        "        registers - a list of strings, if empty no info was available\n",
        "  \"\"\"\n",
        "  # Make a request to Cambridge dictionnary - simply add \"word\" to the url  \n",
        "  url = 'https://dictionary.cambridge.org/dictionary/english/'+word\n",
        "  # Websites don't like it when bots connect to them, so we have to pretend being a web browser! \n",
        "  req = ul.Request(url, headers={'User-Agent': 'Mozilla/5.0'})\n",
        "  client = ul.urlopen(req)\n",
        "  # Read and store data into htmldata \n",
        "  htmldata = client.read()\n",
        "  client.close()\n",
        "\n",
        "  # Create a beautiful soup element and parse it as an html file\n",
        "  parsed_page = soup(htmldata, \"html.parser\")\n",
        "\n",
        "  # A bit of backgrond:\n",
        "  # In order to display the ECFR classification, the website uses <span> tags with a unique CSS class\n",
        "  # The class is called \"epp-xref dxref XX\", where XX is any of the levels A1 to C2\n",
        "  # Now we use 'bs4.find_all' to retrieve all span tag with the given class \n",
        "  # If none are returned, it means the level is not contained in the word \n",
        "\n",
        "  # Tag specific to the ECFR classification CSS class  \n",
        "  class_name_level = \"epp-xref dxref \" \n",
        "\n",
        "  # The ECFR classification spans from A1 to C2, test for each case\n",
        "  cases = np.array([\"A1\", \"A2\", \"B1\", \"B2\", \"C1\", \"C2\"])\n",
        "  # We store the results in a bool vector from A1 to C2, corresponding to the level of the word  \n",
        "  results = []\n",
        "  for case in cases:\n",
        "    # This checks how many times the case is present on page\n",
        "    occurences = len(parsed_page.find_all(\"span\", class_= class_name_level+case))\n",
        "    # If the case is present more than 0 times, then the word can be classified in the given case \n",
        "    if occurences > 0:\n",
        "      results.append(True)\n",
        "    else: \n",
        "      results.append(False) \n",
        "\n",
        "  # Now let's retrieve the registers\n",
        "  # We can apply the same strategy, the register of the word is contained in CSS class \"usage dusage\"\n",
        "\n",
        "  class_name_register = \"usage dusage\"\n",
        "  parsed_registers = parsed_page.find_all(\"span\", class_=class_name_register)\n",
        "  registers = []\n",
        "  for register in parsed_registers:\n",
        "    # Simply extract the information between the tags \"span\" with class class_name_register\n",
        "    registers.append(register.string)\n",
        "\n",
        "  return cases[results], registers"
      ],
      "id": "YdsbflcL0Ns2",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vvSFU4ORe6pE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec5a977-cc5f-4ce6-8412-2cc252f7a498"
      },
      "source": [
        "# Add line for the word you want to look for \n",
        "levels, reg = retrieve_CEFR_levels_registers(\"exhaustive\")\n",
        "print(levels, reg)"
      ],
      "id": "vvSFU4ORe6pE",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C1'] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvxRXiOFvfvU"
      },
      "source": [
        "#### II) CEFR level of sentences\n",
        "\n",
        "Try to implement something similar to `retrieve_ECFR_levels_registers(word)` using the web site [English Profile](http://englishprofile.org/wordlists/text-inspector) for analysing a whole sentence and get the CEFR level of each word (may be better for analysing whole quotes, and does not require stemming.)"
      ],
      "id": "ZvxRXiOFvfvU"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtLZnP7KxwYA"
      },
      "source": [
        "# TODO Quentin, give it a try and see how far I can go "
      ],
      "id": "DtLZnP7KxwYA",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAsd1jJCZkNM"
      },
      "source": [
        "### 3. Create a vocabulary specific to each category in interest"
      ],
      "id": "WAsd1jJCZkNM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsCo8ib4Z0Pr"
      },
      "source": [
        "#### Classify speakers into categories of interest\n",
        "\n",
        "* Each speaker can belong to multiple categories"
      ],
      "id": "YsCo8ib4Z0Pr"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfuNEu7YaHdH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "outputId": "f1eb7de9-d2cf-4998-f839-3d636f0cddcc"
      },
      "source": [
        "df_quotes.sample(10)"
      ],
      "id": "RfuNEu7YaHdH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>quoteID</th>\n",
              "      <th>quotation</th>\n",
              "      <th>speaker</th>\n",
              "      <th>qids</th>\n",
              "      <th>date</th>\n",
              "      <th>numOccurrences</th>\n",
              "      <th>probas</th>\n",
              "      <th>urls</th>\n",
              "      <th>phase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6685</th>\n",
              "      <td>2020-02-09-039076</td>\n",
              "      <td>That was it. We pretty much committed to it th...</td>\n",
              "      <td>Jesse Marshall</td>\n",
              "      <td>[Q1251661]</td>\n",
              "      <td>2020-02-09 03:59:27</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Jesse Marshall, 0.5131], [None, 0.4869]]</td>\n",
              "      <td>[https://calgaryherald.com/life/homes/condos/c...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>823</th>\n",
              "      <td>2020-03-20-027710</td>\n",
              "      <td>I want you to wake up and go `Yes! This speaks...</td>\n",
              "      <td>Blair Williams</td>\n",
              "      <td>[Q19349673, Q54850923]</td>\n",
              "      <td>2020-03-20 08:26:07</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Blair Williams, 0.8063], [None, 0.1937]]</td>\n",
              "      <td>[http://cdapress.com/news/2020/mar/20/art-spir...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3462</th>\n",
              "      <td>2020-02-12-044949</td>\n",
              "      <td>I'll sell to whoever suits me.</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-12 19:05:24</td>\n",
              "      <td>2</td>\n",
              "      <td>[[None, 0.802], [Peter Cairns, 0.198]]</td>\n",
              "      <td>[https://www.stuff.co.nz/waikato-times/news/ta...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1470</th>\n",
              "      <td>2020-03-04-050429</td>\n",
              "      <td>Scott Morrison is finally talking about an eco...</td>\n",
              "      <td>Kate Jones</td>\n",
              "      <td>[Q20235524, Q41718769, Q56867959, Q6375568]</td>\n",
              "      <td>2020-03-04 11:22:02</td>\n",
              "      <td>3</td>\n",
              "      <td>[[Kate Jones, 0.9298], [None, 0.0702]]</td>\n",
              "      <td>[https://www.brisbanetimes.com.au/politics/que...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7894</th>\n",
              "      <td>2020-01-16-016611</td>\n",
              "      <td>Dr Obiora, upon confirmation by the Senate, re...</td>\n",
              "      <td>Muhammadu Buhari</td>\n",
              "      <td>[Q361567]</td>\n",
              "      <td>2020-01-16 00:00:00</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Muhammadu Buhari, 0.8947], [None, 0.0642], [...</td>\n",
              "      <td>[https://punchng.com/buhari-appoints-kingsley-...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2349</th>\n",
              "      <td>2020-03-09-075838</td>\n",
              "      <td>We've got statewide plans for quarantining, an...</td>\n",
              "      <td>Garlin Gilchrist</td>\n",
              "      <td>[Q58323075]</td>\n",
              "      <td>2020-03-09 17:37:08</td>\n",
              "      <td>1</td>\n",
              "      <td>[[Garlin Gilchrist, 0.838], [None, 0.162]]</td>\n",
              "      <td>[https://www.wsjm.com/2020/03/09/lieutenant-go...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7634</th>\n",
              "      <td>2020-02-29-001484</td>\n",
              "      <td>All the students came out and packed the place...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-02-29 03:32:52</td>\n",
              "      <td>1</td>\n",
              "      <td>[[None, 0.9891], [Drew Martin, 0.0109]]</td>\n",
              "      <td>[http://www.bostonglobe.com/sports/high-school...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6445</th>\n",
              "      <td>2020-01-04-027424</td>\n",
              "      <td>People are watching and they understand. Despi...</td>\n",
              "      <td>Yogi Adityanath</td>\n",
              "      <td>[Q4683097]</td>\n",
              "      <td>2020-01-04 14:10:21</td>\n",
              "      <td>10</td>\n",
              "      <td>[[Yogi Adityanath, 0.6763], [None, 0.2946], [P...</td>\n",
              "      <td>[https://www.business-standard.com/article/pti...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1619</th>\n",
              "      <td>2020-01-26-038896</td>\n",
              "      <td>That's not OK because I'm leaning towards Klob...</td>\n",
              "      <td>None</td>\n",
              "      <td>[]</td>\n",
              "      <td>2020-01-26 21:28:33</td>\n",
              "      <td>2</td>\n",
              "      <td>[[None, 0.8026], [Amy Klobuchar, 0.0893], [Eli...</td>\n",
              "      <td>[http://chron.com/news/article/In-Iowa-a-long-...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1223</th>\n",
              "      <td>2020-01-29-062975</td>\n",
              "      <td>Many make the link today between their experie...</td>\n",
              "      <td>Peter Maurer</td>\n",
              "      <td>[Q117796, Q42426597]</td>\n",
              "      <td>2020-01-29 09:04:36</td>\n",
              "      <td>5</td>\n",
              "      <td>[[Peter Maurer, 0.8787], [None, 0.1213]]</td>\n",
              "      <td>[http://whbl.com/news/articles/2020/jan/29/hun...</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                quoteID  ... phase\n",
              "6685  2020-02-09-039076  ...     E\n",
              "823   2020-03-20-027710  ...     E\n",
              "3462  2020-02-12-044949  ...     E\n",
              "1470  2020-03-04-050429  ...     E\n",
              "7894  2020-01-16-016611  ...     E\n",
              "2349  2020-03-09-075838  ...     E\n",
              "7634  2020-02-29-001484  ...     E\n",
              "6445  2020-01-04-027424  ...     E\n",
              "1619  2020-01-26-038896  ...     E\n",
              "1223  2020-01-29-062975  ...     E\n",
              "\n",
              "[10 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0xEuQElTeLr",
        "outputId": "bbf71b63-a7bd-4560-de00-1263d2a80d32"
      },
      "source": [
        "# A small scale test on quote 6685\n",
        "quote_nb = 6685\n",
        "print(\"The quote is: \\n\"+df_quotes.loc[quote_nb].quotation)"
      ],
      "id": "S0xEuQElTeLr",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The quote is: \n",
            "That was it. We pretty much committed to it the next weekend,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAdt0fLlqgbI",
        "outputId": "3660e8ab-a9d5-4b84-994d-b3c3647871a9"
      },
      "source": [
        "# Extract the word 'commited' and get the CEFR (totally empirical, we are waiting on a better tokenizer)\n",
        "levels, reg = retrieve_CEFR_levels_registers(df_quotes.loc[quote_nb].quotation.split()[6])\n",
        "print(levels, reg)"
      ],
      "id": "TAdt0fLlqgbI",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['C2'] []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhXb1auUrkMH"
      },
      "source": [
        "Now get some info about the speaker. Use the data provided in the .parquet file."
      ],
      "id": "mhXb1auUrkMH"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "X0DDAXI6qBYJ",
        "outputId": "22feca57-cae7-4a36-a531-b5a0e54732be"
      },
      "source": [
        "# Find the QID of the speaker \n",
        "QID = df_quotes.loc[quote_nb].qids[0]\n",
        "# Display the known properties for the persone given\n",
        "df_properties = retrieve_wikidata_properties(QID)\n",
        "df_properties"
      ],
      "id": "X0DDAXI6qBYJ",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aliases</th>\n",
              "      <th>date_of_birth</th>\n",
              "      <th>nationality</th>\n",
              "      <th>gender</th>\n",
              "      <th>lastrevid</th>\n",
              "      <th>ethnic_group</th>\n",
              "      <th>US_congress_bio_ID</th>\n",
              "      <th>occupation</th>\n",
              "      <th>party</th>\n",
              "      <th>academic_degree</th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>candidacy</th>\n",
              "      <th>type</th>\n",
              "      <th>religion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7965801</th>\n",
              "      <td>None</td>\n",
              "      <td>[+1980-10-18T00:00:00Z]</td>\n",
              "      <td>[Q30]</td>\n",
              "      <td>[Q6581097]</td>\n",
              "      <td>1323455881</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>[Q4144610]</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>Q1251661</td>\n",
              "      <td>Jesse Marshall</td>\n",
              "      <td>None</td>\n",
              "      <td>item</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        aliases            date_of_birth nationality  ... candidacy  type religion\n",
              "7965801    None  [+1980-10-18T00:00:00Z]       [Q30]  ...      None  item     None\n",
              "\n",
              "[1 rows x 15 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1zaw5eMbUZO",
        "outputId": "c2a731c7-ffc5-43c8-dbe1-f83bce9a8f06"
      },
      "source": [
        "# Retrieve the occupation in human readable format \n",
        "human_readable_properties(df_properties, \"occupation\")"
      ],
      "id": "K1zaw5eMbUZO",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['alpine skier']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byfmb6mNFp5c",
        "outputId": "d941c523-d2ae-40ea-fec8-da964df02612"
      },
      "source": [
        "# Retrieve the nationality in human readable format \n",
        "human_readable_properties(df_properties, \"nationality\")"
      ],
      "id": "byfmb6mNFp5c",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['United States of America']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aXmSQ-4MNDp5",
        "outputId": "63ceafb4-1922-4d60-a6c0-831e909cc7b1"
      },
      "source": [
        "# Retrieve the candidacy in human readable format \n",
        "human_readable_properties(df_properties, \"candidacy\")"
      ],
      "id": "aXmSQ-4MNDp5",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: There is no value for this property!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfCz594iVL_M"
      },
      "source": [
        "## D) Data analysis\n",
        "\n",
        "For now, this section only contains code that we will eventually use later."
      ],
      "id": "XfCz594iVL_M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asFKAikJRb6d"
      },
      "source": [
        "##### nltk.collocations without POS tags"
      ],
      "id": "asFKAikJRb6d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6OKqaPTB_4R"
      },
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "PUNCTUATION = set(string.punctuation)  # Punctuation\n",
        "EN_STOPWORDS = set(stopwords.words(\"english\"))  # English stopwords\n",
        "\n",
        "def format_quote_for_collocation_finder(l):\n",
        "    newL = [w.lower() for w in l]  # lowercase everything\n",
        "    newL = [\"<P>\" if w in PUNCTUATION else w for w in newL]  # We don't remove punctuation yet, as they act as separators between words, which we need to construct meaningful bigrams for collocation finding. Instead, we replace them by a punctuation tag\n",
        "    newL = [\"<S>\" if w in EN_STOPWORDS else w for w in newL]  # We don't remove the stopwords yet, as they act as separators between non-stopwords which we need to construct meaningful bigrams for collocation finding. Instead, we replace them by a stopword tag\n",
        "    # We add starting and ending tags to mark end of quotes and avoid constructing bigrams of the end word of a quote and the start word of the next one which is unrelated.\n",
        "    newL.insert(0, \"<B>\")  # Add begin tag\n",
        "    newL.append(\"<E>\")  # Add end tag\n",
        "    return newL\n",
        "\n",
        "marked_quotes = quotes_selected_speakers.tokenized_quote.apply(format_quote_for_collocation_finder)\n",
        "all_marked_quotes = [token for l in marked_quotes for token in l]"
      ],
      "id": "K6OKqaPTB_4R",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ww0tgy1IIt3"
      },
      "source": [
        "from nltk.collocations import BigramCollocationFinder, BigramAssocMeasures\n",
        "\n",
        "bigram_measures = BigramAssocMeasures()\n",
        "finder = BigramCollocationFinder.from_words(all_marked_quotes)\n",
        "\n",
        "frequency = 4  # Minimum number of occurences of the bigram\n",
        "finder.apply_freq_filter(frequency)\n",
        "\n",
        "finder.nbest(bigram_measures.pmi, 15)  # n most collocated words\n",
        "#finder.score_ngrams(bigram_measures.pmi)  # Scores"
      ],
      "id": "4ww0tgy1IIt3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6U337IMRoHi"
      },
      "source": [
        "##### nltk.collocations with POS tags"
      ],
      "id": "T6U337IMRoHi"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytxhJDlEJbCP"
      },
      "source": [
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def format_quote_for_collocation_finder_tagged(l):\n",
        "    newL = nltk.pos_tag(l)\n",
        "    newL = [(w.lower(), tag) for (w, tag) in newL]  # lowercase everything\n",
        "    newL = [(\"<P>\", \"TAG-P\") if w in PUNCTUATION else (w, tag) for (w, tag) in newL]  # We don't remove punctuation yet, as they act as separators between words, which we need to construct meaningful bigrams for collocation finding. Instead, we replace them by a punctuation tag\n",
        "    newL = [(\"<S>\", \"TAG-S\") if w in EN_STOPWORDS else (w, tag) for (w, tag) in newL]  # We don't remove the stopwords yet, as they act as separators between non-stopwords which we need to construct meaningful bigrams for collocation finding. Instead, we replace them by a stopword tag\n",
        "    # We add starting and ending tags to mark end of quotes and avoid constructing bigrams of the end word of a quote and the start word of the next one which is unrelated.\n",
        "    newL.insert(0, (\"<B>\", \"TAG-B\"))  # Add begin tag with random POS tag\n",
        "    newL.append((\"<E>\", \"TAG-E\"))  # Add end tag with random POS tag\n",
        "    return newL\n",
        "\n",
        "marked_quotes_tagged = quotes_selected_speakers.tokenized_quote.apply(format_quote_for_collocation_finder_tagged)\n",
        "all_marked_quotes_tagged = [token for l in marked_quotes_tagged for token in l]"
      ],
      "id": "ytxhJDlEJbCP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkyqkB4tJ0Fr"
      },
      "source": [
        "finder_tagged = BigramCollocationFinder.from_words(all_marked_quotes_tagged)\n",
        "frequency_tagged = 3\n",
        "finder_tagged.apply_freq_filter(frequency_tagged)\n",
        "finder_tagged.nbest(bigram_measures.pmi, 15)  # n most collocated words"
      ],
      "id": "tkyqkB4tJ0Fr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jhabGmPRrG7"
      },
      "source": [
        "##### Named entity recognition"
      ],
      "id": "8jhabGmPRrG7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XNH7i6NHRvGr"
      },
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "ner_quotes = quotes_selected_speakers.tokenized_quote.apply(nltk.pos_tag)\n",
        "ner_quotes = ner_quotes.apply(nltk.ne_chunk)\n",
        "ner_quotes.head()"
      ],
      "id": "XNH7i6NHRvGr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkxdMFL6VpT6"
      },
      "source": [
        "print(ner_quotes[86])"
      ],
      "id": "FkxdMFL6VpT6",
      "execution_count": null,
      "outputs": []
    }
  ]
}